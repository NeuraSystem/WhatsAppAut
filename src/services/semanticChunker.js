#!/usr/bin/env node

// src/services/semanticChunker.js
// CHUNKING SEM√ÅNTICO CON OVERLAP - SOLUCI√ìN CR√çTICA 2
// Implementa ventana deslizante para mejorar coherencia conversacional

const logger = require("../utils/logger");
const { embeddingEngine } = require("./embeddingEngine");

/**
 * SEMANTIC CHUNKER CON OVERLAP INTELIGENTE
 * Basado en Plan Estrat√©gico Soluci√≥n Cr√≠tica 2
 *
 * Funcionalidades:
 * - Ventana deslizante con overlap configurable
 * - Contexto conversacional preservado
 * - Metadata enriquecida con flujo de conversaci√≥n
 * - Patrones espec√≠ficos para SalvaCell
 */
class SemanticChunker {
  constructor(options = {}) {
    // Configuraci√≥n por defecto basada en an√°lisis de SalvaCell
    this.config = {
      // Ventana base para conversaciones generales
      defaultWindowSize: 3,
      defaultOverlapSize: 1,
      maxChunkLength: 1000,

      // Patrones espec√≠ficos de SalvaCell
      patterns: {
        PRICE_INQUIRY_FLOW: {
          pattern: ["device_inquiry", "price_request", "availability_check"],
          windowSize: 3,
          overlapSize: 2,
        },
        WARRANTY_CLAIM_FLOW: {
          pattern: ["repair_history", "issue_description", "warranty_request"],
          windowSize: 4,
          overlapSize: 2,
        },
        MULTI_DEVICE_FAMILY: {
          pattern: ["device_1", "device_2", "comparison_request"],
          windowSize: 5,
          overlapSize: 3,
        },
        TIMING_CONSULTATION: {
          pattern: ["service_inquiry", "timing_request", "decision_pending"],
          windowSize: 3,
          overlapSize: 2,
        },
      },

      // Integraci√≥n con informaci√≥n Markdown
      useMarkdownContext: true,
      markdownKeywords: [
        "establecimiento",
        "domicilio",
        "4 PM",
        "garant√≠a",
        "original",
        "gen√©rica",
      ],

      ...options,
    };

    // Buffer circular para mantener conversaciones recientes
    this.conversationBuffer = new Map(); // clientId -> Array<ConversationEntry>
    this.patternAnalyzer = new ConversationPatternAnalyzer();

    logger.info("üîÑ SemanticChunker inicializado con configuraci√≥n:", {
      windowSize: this.config.defaultWindowSize,
      overlapSize: this.config.defaultOverlapSize,
      patterns: Object.keys(this.config.patterns).length,
    });
  }

  /**
   * M√âTODO PRINCIPAL: Crear chunks sem√°nticos con overlap
   *
   * @param {string} clientId - ID del cliente
   * @param {string} userMessage - Mensaje del usuario
   * @param {string} botResponse - Respuesta del bot
   * @param {string} intent - Intenci√≥n detectada
   * @param {Object} extractedData - Datos extra√≠dos
   * @returns {Promise<Array>} Array de chunks con contexto y overlap
   */
  async createSemanticChunks(
    clientId,
    userMessage,
    botResponse,
    intent,
    extractedData = {},
  ) {
    try {
      // 1. Crear entrada de conversaci√≥n actual
      const conversationEntry = this.createConversationEntry(
        clientId,
        userMessage,
        botResponse,
        intent,
        extractedData,
      );

      // 2. Actualizar buffer circular
      this.updateConversationBuffer(clientId, conversationEntry);

      // 3. Detectar patr√≥n conversacional
      const detectedPattern = this.patternAnalyzer.detectPattern(
        this.getClientConversations(clientId),
      );

      // 4. Configurar ventana seg√∫n patr√≥n
      const windowConfig = this.getWindowConfig(detectedPattern);

      // 5. Crear chunks con ventana deslizante
      const chunks = await this.createSlidingWindowChunks(
        clientId,
        conversationEntry,
        windowConfig,
      );

      logger.info(`üîÑ Chunks sem√°nticos creados para ${clientId}:`, {
        pattern: detectedPattern,
        chunks: chunks.length,
        windowSize: windowConfig.windowSize,
        overlapSize: windowConfig.overlapSize,
      });

      return chunks;
    } catch (error) {
      logger.error("Error creando chunks sem√°nticos:", error);
      // Fallback a chunk simple
      return [
        await this.createFallbackChunk(
          clientId,
          userMessage,
          botResponse,
          intent,
          extractedData,
        ),
      ];
    }
  }

  /**
   * CREAR CHUNKS CON VENTANA DESLIZANTE
   * Implementa overlap sem√°ntico seg√∫n documentaci√≥n LangChain
   *
   * @param {string} clientId - ID del cliente
   * @param {Object} currentEntry - Entrada actual
   * @param {Object} windowConfig - Configuraci√≥n de ventana
   * @returns {Promise<Array>} Chunks con overlap
   */
  async createSlidingWindowChunks(clientId, currentEntry, windowConfig) {
    const chunks = [];
    const conversations = this.getClientConversations(clientId);
    const { windowSize, overlapSize } = windowConfig;

    // Si no hay suficiente historial, crear chunk simple
    if (conversations.length < windowSize) {
      const chunk = await this.createContextualChunk(
        conversations,
        conversations.length - 1,
        currentEntry,
        "simple",
      );
      chunks.push(chunk);
      return chunks;
    }

    // Crear ventana deslizante con overlap
    for (let i = 0; i < conversations.length; i++) {
      const windowStart = Math.max(0, i - Math.floor(windowSize / 2));
      const windowEnd = Math.min(
        conversations.length,
        windowStart + windowSize,
      );
      const contextWindow = conversations.slice(windowStart, windowEnd);

      // Determinar √≠ndice focal dentro de la ventana
      const focusIndex = i - windowStart;

      // Crear chunk contextual con overlap
      const chunk = await this.createContextualChunk(
        contextWindow,
        focusIndex,
        currentEntry,
        "windowed",
      );

      chunks.push(chunk);

      // Implementar overlap: si no es el √∫ltimo chunk, avanzar solo por (windowSize - overlapSize)
      if (i < conversations.length - 1) {
        i += Math.max(1, windowSize - overlapSize) - 1; // -1 porque el for loop incrementa
      }
    }

    return chunks;
  }

  /**
   * CREAR CHUNK CONTEXTUAL CON OVERLAP
   * Estructura: [CONTEXTO PREVIO] + [CONVERSACI√ìN PRINCIPAL] + [CONTEXTO POSTERIOR]
   *
   * @param {Array} contextWindow - Ventana de conversaciones
   * @param {number} focusIndex - √çndice de la conversaci√≥n principal
   * @param {Object} currentEntry - Entrada actual
   * @param {string} type - Tipo de chunk ('simple' o 'windowed')
   * @returns {Promise<Object>} Chunk con contexto y metadata
   */
  async createContextualChunk(
    contextWindow,
    focusIndex,
    currentEntry,
    type = "windowed",
  ) {
    const primaryConversation = contextWindow[focusIndex];
    const timestamp = new Date().toISOString();

    // 1. CONSTRUIR TEXTO CONTEXTUAL
    let chunkText = "";

    // [CONTEXTO PREVIO] - Overlap anterior
    if (focusIndex > 0 && type === "windowed") {
      chunkText += "[CONTEXTO PREVIO]\n";
      for (let i = 0; i < focusIndex; i++) {
        const conv = contextWindow[i];
        chunkText += `Usuario: "${conv.userMessage}" -> Sofia: "${conv.botResponse}"\n`;
      }
      chunkText += "\n";
    }

    // [CONVERSACI√ìN PRINCIPAL] - Foco actual
    chunkText += "[CONVERSACI√ìN PRINCIPAL]\n";
    chunkText += `[Cliente ${primaryConversation.clientId}] `;
    chunkText += `Usuario: "${primaryConversation.userMessage}" -> `;
    chunkText += `Sofia: "${primaryConversation.botResponse}"\n`;

    // [CONTEXTO POSTERIOR] - Overlap posterior
    if (focusIndex < contextWindow.length - 1 && type === "windowed") {
      chunkText += "\n[CONTEXTO POSTERIOR]\n";
      for (let i = focusIndex + 1; i < contextWindow.length; i++) {
        const conv = contextWindow[i];
        chunkText += `Usuario: "${conv.userMessage}" -> Sofia: "${conv.botResponse}"\n`;
      }
    }

    // 2. INTEGRAR INFORMACI√ìN MARKDOWN SI APLICA
    if (this.config.useMarkdownContext) {
      const markdownContext = this.extractMarkdownContext(primaryConversation);
      if (markdownContext) {
        chunkText += "\n[INFORMACI√ìN CONTEXTUAL]\n";
        chunkText += markdownContext;
      }
    }

    // 3. CREAR METADATA ENRIQUECIDA
    const metadata = this.buildEnhancedMetadata(
      primaryConversation,
      contextWindow,
      currentEntry,
      type,
    );

    // 4. VALIDAR LONGITUD
    if (chunkText.length > this.config.maxChunkLength) {
      chunkText = this.truncateChunk(chunkText, this.config.maxChunkLength);
      metadata.truncated = true;
    }

    return {
      id: `semantic_${primaryConversation.clientId}_${Date.now()}_${focusIndex}`,
      text: chunkText,
      metadata: metadata,
      type: type,
      timestamp: timestamp,
    };
  }

  /**
   * EXTRAER CONTEXTO MARKDOWN RELEVANTE
   * Integra informaci√≥n de archivos Markdown de precios seg√∫n contexto
   *
   * @param {Object} conversation - Conversaci√≥n principal
   * @returns {string|null} Contexto Markdown relevante
   */
  extractMarkdownContext(conversation) {
    const { userMessage, botResponse, intent, extractedData } = conversation;
    let context = "";

    // Detectar si se mencionan temas relacionados con tiempos
    if (
      this.containsAny(userMessage + " " + botResponse, [
        "tiempo",
        "cu√°nto",
        "demora",
        "domicilio",
        "establecimiento",
      ])
    ) {
      context +=
        "‚Ä¢ Tiempo establecimiento: Mismo d√≠a (antes 4PM) / Siguiente d√≠a (despu√©s 4PM)\n";
      context += "‚Ä¢ Tiempo domicilio: 45-60 minutos una vez iniciado\n";
    }

    // Detectar si se mencionan temas relacionados con garant√≠as
    if (
      this.containsAny(userMessage + " " + botResponse, [
        "garant√≠a",
        "original",
        "gen√©rica",
        "calidad",
      ])
    ) {
      context += "‚Ä¢ Garant√≠a original: 30 d√≠as\n";
      context += "‚Ä¢ Garant√≠a gen√©rica: 15 d√≠as\n";
    }

    // Detectar si se mencionan precios espec√≠ficos
    if (
      extractedData.device &&
      (intent === "consulta_precio" || botResponse.includes("$"))
    ) {
      context += `‚Ä¢ Informaci√≥n de precios disponible para ${extractedData.device}\n`;
    }

    return context.trim() || null;
  }

  /**
   * CONSTRUIR METADATA ENRIQUECIDA
   * Incluye an√°lisis de flujo conversacional y contexto sem√°ntico
   *
   * @param {Object} primaryConversation - Conversaci√≥n principal
   * @param {Array} contextWindow - Ventana de contexto
   * @param {Object} currentEntry - Entrada actual
   * @param {string} type - Tipo de chunk
   * @returns {Object} Metadata enriquecida
   */
  buildEnhancedMetadata(
    primaryConversation,
    contextWindow,
    currentEntry,
    type,
  ) {
    const conversationFlow = this.analyzeConversationFlow(contextWindow);
    const semanticDensity = this.calculateSemanticDensity(contextWindow);

    return {
      // Metadata original
      client_id: primaryConversation.clientId,
      main_intent: primaryConversation.intent,
      device_mentioned: primaryConversation.extractedData.device || "",
      service_mentioned: primaryConversation.extractedData.service || "",
      price_quoted: primaryConversation.extractedData.price || "",

      // Metadata de contexto sem√°ntico
      context_window_size: contextWindow.length,
      conversation_flow: conversationFlow,
      semantic_density: semanticDensity,
      chunk_type: type,
      focus_index: contextWindow.indexOf(primaryConversation),

      // Metadata de patrones conversacionales
      detected_pattern: this.patternAnalyzer.detectPattern(contextWindow),
      flow_stage: this.determineFlowStage(contextWindow, primaryConversation),
      continuity_score: this.calculateContinuityScore(contextWindow),

      // Metadata temporal
      timestamp: primaryConversation.timestamp,
      hour_of_day: this.getHourCategory(
        new Date(primaryConversation.timestamp),
      ),

      // Metadata de contenido
      has_markdown_context: this.config.useMarkdownContext,
      markdown_keywords: this.extractMarkdownKeywords(primaryConversation),

      // Metadata de calidad
      chunk_length: 0, // Se actualizar√° despu√©s
      has_price_info: primaryConversation.extractedData.price ? "yes" : "no",
      has_device_info: primaryConversation.extractedData.device ? "yes" : "no",
      response_type: this.classifyResponseType(primaryConversation.botResponse),
    };
  }

  /**
   * ANALIZAR FLUJO CONVERSACIONAL
   * Identifica patrones y progresi√≥n de la conversaci√≥n
   *
   * @param {Array} contextWindow - Ventana de conversaciones
   * @returns {string} Tipo de flujo identificado
   */
  analyzeConversationFlow(contextWindow) {
    const intents = contextWindow.map((conv) => conv.intent);
    const devices = contextWindow
      .map((conv) => conv.extractedData.device)
      .filter(Boolean);
    const prices = contextWindow
      .map((conv) => conv.extractedData.price)
      .filter(Boolean);

    // Detectar patrones espec√≠ficos de SalvaCell
    if (
      intents.includes("consulta_precio") &&
      intents.includes("consulta_disponibilidad")
    ) {
      return "price_to_availability";
    }

    if (devices.length > 1) {
      return "multi_device_comparison";
    }

    if (intents.includes("saludo") && intents.includes("consulta_precio")) {
      return "greeting_to_inquiry";
    }

    if (prices.length > 0 && intents.includes("agradecimiento")) {
      return "inquiry_to_closing";
    }

    return "general_conversation";
  }

  /**
   * CALCULAR DENSIDAD SEM√ÅNTICA
   * Mide la riqueza de informaci√≥n en la ventana de contexto
   *
   * @param {Array} contextWindow - Ventana de conversaciones
   * @returns {number} Puntuaci√≥n de densidad sem√°ntica (0-1)
   */
  calculateSemanticDensity(contextWindow) {
    let score = 0;
    let factors = 0;

    // Factor 1: Diversidad de intenciones
    const uniqueIntents = new Set(contextWindow.map((conv) => conv.intent));
    score += uniqueIntents.size / Math.max(contextWindow.length, 1);
    factors++;

    // Factor 2: Informaci√≥n extra√≠da
    const extractedInfo = contextWindow.reduce(
      (acc, conv) => {
        if (conv.extractedData.device)
          acc.devices.add(conv.extractedData.device);
        if (conv.extractedData.service)
          acc.services.add(conv.extractedData.service);
        if (conv.extractedData.price) acc.prices.add(conv.extractedData.price);
        return acc;
      },
      { devices: new Set(), services: new Set(), prices: new Set() },
    );

    const infoRichness =
      (extractedInfo.devices.size +
        extractedInfo.services.size +
        extractedInfo.prices.size) /
      (contextWindow.length * 3);
    score += infoRichness;
    factors++;

    // Factor 3: Longitud promedio de mensajes
    const avgLength =
      contextWindow.reduce((sum, conv) => sum + conv.userMessage.length, 0) /
      contextWindow.length;
    score += Math.min(avgLength / 100, 1); // Normalizar a 100 caracteres
    factors++;

    return score / factors;
  }

  /**
   * DETERMINAR ETAPA DEL FLUJO
   * Identifica en qu√© etapa se encuentra la conversaci√≥n
   *
   * @param {Array} contextWindow - Ventana de conversaciones
   * @param {Object} primaryConversation - Conversaci√≥n principal
   * @returns {string} Etapa del flujo
   */
  determineFlowStage(contextWindow, primaryConversation) {
    const position = contextWindow.indexOf(primaryConversation);
    const totalLength = contextWindow.length;

    if (position === 0) return "opening";
    if (position === totalLength - 1) return "current";
    if (position / totalLength < 0.3) return "early";
    if (position / totalLength > 0.7) return "late";
    return "middle";
  }

  /**
   * CALCULAR PUNTUACI√ìN DE CONTINUIDAD
   * Mide qu√© tan bien conectadas est√°n las conversaciones
   *
   * @param {Array} contextWindow - Ventana de conversaciones
   * @returns {number} Puntuaci√≥n de continuidad (0-1)
   */
  calculateContinuityScore(contextWindow) {
    if (contextWindow.length < 2) return 1.0;

    let continuityScore = 0;
    let connections = 0;

    for (let i = 1; i < contextWindow.length; i++) {
      const prev = contextWindow[i - 1];
      const curr = contextWindow[i];

      // Verificar continuidad tem√°tica
      if (
        prev.extractedData.device === curr.extractedData.device &&
        prev.extractedData.device
      ) {
        continuityScore += 0.3;
      }

      // Verificar continuidad de servicio
      if (
        prev.extractedData.service === curr.extractedData.service &&
        prev.extractedData.service
      ) {
        continuityScore += 0.2;
      }

      // Verificar continuidad de intenci√≥n
      if (this.areRelatedIntents(prev.intent, curr.intent)) {
        continuityScore += 0.3;
      }

      // Verificar continuidad temporal (menos de 30 minutos)
      const timeDiff = Math.abs(
        new Date(curr.timestamp) - new Date(prev.timestamp),
      );
      if (timeDiff < 30 * 60 * 1000) {
        // 30 minutos
        continuityScore += 0.2;
      }

      connections++;
    }

    return connections > 0 ? continuityScore / connections : 0;
  }

  /**
   * VERIFICAR INTENCIONES RELACIONADAS
   * Determina si dos intenciones est√°n relacionadas sem√°nticamente
   *
   * @param {string} intent1 - Primera intenci√≥n
   * @param {string} intent2 - Segunda intenci√≥n
   * @returns {boolean} True si est√°n relacionadas
   */
  areRelatedIntents(intent1, intent2) {
    const relatedGroups = [
      ["saludo", "consulta_precio", "consulta_disponibilidad"],
      ["consulta_precio", "consulta_disponibilidad", "agradecimiento"],
      ["queja", "escalar_a_humano"],
      ["consulta_ubicacion", "consulta_horario"],
    ];

    return relatedGroups.some(
      (group) => group.includes(intent1) && group.includes(intent2),
    );
  }

  /**
   * EXTRAER PALABRAS CLAVE MARKDOWN
   * Identifica palabras clave relacionadas con informaci√≥n Markdown
   *
   * @param {Object} conversation - Conversaci√≥n
   * @returns {Array} Array de palabras clave encontradas
   */
  extractMarkdownKeywords(conversation) {
    const text = conversation.userMessage + " " + conversation.botResponse;
    return this.config.markdownKeywords.filter((keyword) =>
      text.toLowerCase().includes(keyword.toLowerCase()),
    );
  }

  /**
   * M√âTODOS AUXILIARES
   */

  createConversationEntry(
    clientId,
    userMessage,
    botResponse,
    intent,
    extractedData,
  ) {
    return {
      clientId,
      userMessage,
      botResponse,
      intent,
      extractedData,
      timestamp: new Date().toISOString(),
    };
  }

  updateConversationBuffer(clientId, entry) {
    if (!this.conversationBuffer.has(clientId)) {
      this.conversationBuffer.set(clientId, []);
    }

    const buffer = this.conversationBuffer.get(clientId);
    buffer.push(entry);

    // Mantener solo las √∫ltimas 20 conversaciones por cliente
    if (buffer.length > 20) {
      buffer.shift();
    }

    this.conversationBuffer.set(clientId, buffer);
  }

  getClientConversations(clientId) {
    return this.conversationBuffer.get(clientId) || [];
  }

  getWindowConfig(detectedPattern) {
    const patternConfig = this.config.patterns[detectedPattern];
    if (patternConfig) {
      return {
        windowSize: patternConfig.windowSize,
        overlapSize: patternConfig.overlapSize,
      };
    }

    return {
      windowSize: this.config.defaultWindowSize,
      overlapSize: this.config.defaultOverlapSize,
    };
  }

  async createFallbackChunk(
    clientId,
    userMessage,
    botResponse,
    intent,
    extractedData,
  ) {
    return {
      id: `fallback_${clientId}_${Date.now()}`,
      text: `[Conversaci√≥n con ${clientId}] Usuario: '${userMessage}' -> Sofia: '${botResponse}'`,
      metadata: {
        client_id: clientId,
        main_intent: intent,
        device_mentioned: extractedData.device || "",
        service_mentioned: extractedData.service || "",
        price_quoted: extractedData.price || "",
        chunk_type: "fallback",
        timestamp: new Date().toISOString(),
      },
      type: "fallback",
      timestamp: new Date().toISOString(),
    };
  }

  truncateChunk(text, maxLength) {
    if (text.length <= maxLength) return text;

    // Truncar preservando estructura
    const truncated = text.substring(0, maxLength - 50);
    const lastNewline = truncated.lastIndexOf("\n");

    if (lastNewline > maxLength * 0.8) {
      return truncated.substring(0, lastNewline) + "\n[...TRUNCADO...]";
    }

    return truncated + "\n[...TRUNCADO...]";
  }

  containsAny(text, keywords) {
    const lowerText = text.toLowerCase();
    return keywords.some((keyword) =>
      lowerText.includes(keyword.toLowerCase()),
    );
  }

  classifyResponseType(response) {
    if (response.includes("$") || response.includes("precio"))
      return "price_quote";
    if (response.includes("minutos") || response.includes("tiempo"))
      return "time_estimate";
    if (response.includes("disponible")) return "availability";
    if (response.includes("Hola") || response.includes("soy Sofia"))
      return "greeting";
    if (response.includes("gracias") || response.includes("Perfecto"))
      return "closing";
    return "information";
  }

  getHourCategory(date) {
    const hour = date.getHours();
    if (hour >= 6 && hour < 12) return "ma√±ana";
    if (hour >= 12 && hour < 18) return "tarde";
    return "noche";
  }

  /**
   * OBTENER ESTAD√çSTICAS DEL CHUNKER
   *
   * @returns {Object} Estad√≠sticas de uso
   */
  getChunkerStats() {
    const totalClients = this.conversationBuffer.size;
    const totalConversations = Array.from(
      this.conversationBuffer.values(),
    ).reduce((sum, buffer) => sum + buffer.length, 0);

    return {
      total_clients: totalClients,
      total_conversations: totalConversations,
      average_conversations_per_client:
        totalClients > 0 ? totalConversations / totalClients : 0,
      patterns_configured: Object.keys(this.config.patterns).length,
      markdown_integration: this.config.useMarkdownContext,
    };
  }
}

/**
 * ANALIZADOR DE PATRONES CONVERSACIONALES
 * Detecta autom√°ticamente patrones en las conversaciones
 */
class ConversationPatternAnalyzer {
  constructor() {
    this.patterns = {
      PRICE_INQUIRY_FLOW: [
        "saludo",
        "consulta_precio",
        "consulta_disponibilidad",
      ],
      WARRANTY_CLAIM_FLOW: ["queja", "escalar_a_humano"],
      MULTI_DEVICE_FAMILY: [
        "consulta_precio",
        "consulta_precio",
        "consulta_precio",
      ],
      TIMING_CONSULTATION: ["consulta_precio", "consulta_horario"],
    };
  }

  detectPattern(conversations) {
    if (conversations.length < 2) return "SIMPLE_CONVERSATION";

    const recentIntents = conversations.slice(-4).map((conv) => conv.intent);

    // Verificar patrones espec√≠ficos
    for (const [patternName, patternIntents] of Object.entries(this.patterns)) {
      if (this.matchesPattern(recentIntents, patternIntents)) {
        return patternName;
      }
    }

    // Detectar patrones din√°micos
    const uniqueDevices = new Set(
      conversations.map((conv) => conv.extractedData.device).filter(Boolean),
    );
    if (uniqueDevices.size > 1) {
      return "MULTI_DEVICE_FAMILY";
    }

    const hasPriceQuotes = conversations.some(
      (conv) => conv.extractedData.price,
    );
    const hasTimeQuestions = conversations.some(
      (conv) =>
        conv.userMessage.toLowerCase().includes("tiempo") ||
        conv.userMessage.toLowerCase().includes("cu√°nto"),
    );

    if (hasPriceQuotes && hasTimeQuestions) {
      return "TIMING_CONSULTATION";
    }

    return "GENERAL_CONVERSATION";
  }

  matchesPattern(intents, patternIntents) {
    if (intents.length < patternIntents.length) return false;

    for (let i = 0; i <= intents.length - patternIntents.length; i++) {
      let matches = true;
      for (let j = 0; j < patternIntents.length; j++) {
        if (intents[i + j] !== patternIntents[j]) {
          matches = false;
          break;
        }
      }
      if (matches) return true;
    }

    return false;
  }
}

module.exports = {
  SemanticChunker,
  ConversationPatternAnalyzer,
};
